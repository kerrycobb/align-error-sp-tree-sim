\section{Introduction}

Shared ancestry is a fundamental attribute of life and phylogenetic methods 
provide a statistical basis for understanding the evolutionary history of organisms.
A significant challenge to phylogentic reconstructions of this history is the 
discordance that can arise between the genealogical histories of genes and 
histories of divergence among species \citep{maddisonGeneTreesSpecies1997}.
Of the processes that lead to this phenomenon, incomplete lineage sorting has 
been the focus of most phylogenetic methods development to account for discordance
among gene trees. The multispecie coalescent (MSC) model has emerged as a 
powerful framework for estimating species trees along with other parameters of 
interest such as divergence times, and effective population sizes in the 
presence of incomplete lineage sorting \citep{xuChallengesSpeciesTree2016}.
Full-likelihood Bayesian approaches are appealing, because of their ability to
infer the species tree directly from character alignments while accommodating
uncertainty in geneaological processes by integrating over gene trees
\citep{rannalaEfficientBayesianSpecies2017}.
%% This categorization does not capture methods that use phylogenetic invariants
% There are two classes of methods using the MSC model: approximate or summary 
% methods and full Likelihood methods. Full likelihood methods are ideal because they 
% integrate over gene trees and accomodate uncertainty, whereas summary methods 
% treat gene trees as observed data and are thus susceptible to bias arising from 
% error in gene tree estimation \citep{rannalaEfficientBayesianSpecies2017}.

Full likelihood approaches to species 
tree inference can be
% further
classified into two groups, based on how they model the 
evolution of orthologous DNA sites along gene trees within the species 
tree---those that assume (1) each site evolved along its own gene tree 
(i.e., each site is ``unlinked'') 
\citep{bryantInferringSpeciesTrees2012, maioPoMoAlleleFrequencyBased2015}, 
or (2) contiguous, linked sites evolved along a shared gene tree 
\citep{liuSpeciesTreesGene2007, Heled2010, ogilvieStarBEAST2BringsFaster2017, 
yangBPPProgramSpecies2015}. We will refer to these as unlinked and 
linked-character models, respectively. For both models, the gene tree of each 
locus (whether each locus is a single site or a segment of linked sites) 
is assumed to be independent of the gene 
trees of all other loci, conditional on the species tree.
Methods using linked character models become computationally expensive as the
number of loci grows large, due to the estimation or numerical integration of
all of the gene trees \citep{bryantInferringSpeciesTrees2012}.
Unlinked-character models on the other 
hand are more tractable for a large number of loci, because  estimating 
individual gene trees is avoided by integrating over all possible gene trees 
\citep{bryantInferringSpeciesTrees2012}.
Whereas unlinked-character models can accomodate a larger number of loci than
linked-character models, most genetic data sets comprise linked sites and
unlinked-character models are unable to utilize this information.

Reduced-representation genomic data sets acquired from high-throughput
instruments are becoming commonplace in phylogenetics \citep{Leache2017}, and
usually comprise hundreds to thousands of loci as short as 50 nucleotides long
and up to several thousand base pairs long.
Investigators are thus faced with decisions about how best to 
use their data to infer a species tree.
Should they use a linked-character method that assumes the sites within each
locus evolved along a shared gene tree?
Ideally, the answer would be ``yes,'' however this is not always
computationally feasible and the model could be violated by intralocus
recombination.
Alternatively, should investigators remove all but a single-nucleotide
polymorphism (SNP) from each locus and use an unlinked-character model?
Or, perhaps they should apply the unlinked-character method to all of their
sites, even if this violates the assumption that each site evolved along an
independent gene tree?
Little work has been done to help inform these types of decisions. 

An important consideration for choosing a multi-species coalescent model is
the sources of error and bias that result from reduced-representation protocols,
high-throughput sequencing technologies, and the processing of these data.
Most reduced-representation sequencing workflows employ amplification of DNA  
using polymerase chain reaction (PCR) which can introduce mutational error at a 
rate of up to $1.5\times10^{-5}$ substitutions per base \citep{potapovExaminingSourcesError2017}.
Furthermore, amplification of different genome regions can be highly variable 
resulting in uneven coverage across loci \citep{airdAnalyzingMinimizingPCR2011}. 
Current high-throughput sequencing technologies have high rates of error.
For example, Illumina sequencing platforms have been shown to have error rates
as high as 0.25\% per base. 

\citep{pfeifferSystematicEvaluationError2018}. 
To avoid introducing sequencing errors into analyses performed with the data, it is not 
uncommon to filter out variants that are not found above some minimum frequency 
threshold \citep{rochetteStacksAnalyticalMethods2019, linckMinorAlleleFrequency2019}. 
The effect of this filtering will be more pronounced in data sets with low or 
highly variable coverage.
This filtering can also introduce errors and biases which has been 
shown to have an effect on estimates derived from the assembled alignments
\citep{Harvey2015,linckMinorAlleleFrequency2019}.
Furthermore, decisions have to be made during or after processing
the raw sequence reads to avoid aligning paralogous sequences.
This is often done by setting an upper threshold on the number of variable
sites within a locus \citep{harveySimilarityThresholdsUsed2015}. 
Such a strategy will also filter out the most variable alignments
of orthologous loci, thus introducing an acquisition bias.

Given all of these potential problems throughout the data collection process,
phylogeneticists should assume their high-throughput genomic data set suffers
from errors and acquisition biases.
Do linked and unlinked character models differ in their robustness to such
errors?
Linked-character models can leverage shared information among linked sites
about each underlying gene tree.
Thus, these models may be able to correctly infer the general shape and depth
of a gene tree, even if the haplotypes at some of the tips have errors.
Unlinked character models have very little information about each gene tree,
and rely on the frequency of allele counts across many characters to inform the
model about the relative probabilities of all possible gene trees
(\jrocomment{Figure showing this difference?}).
Given this reliance on accurate allele count frequencies, we predict that
unlinked character models will be more sensitive to errors and acquisition
biases in genomic data.
Our goal is to simulate data sets with varying degrees of errors length of loci
to test this prediction that linked character models are more robust to the
types of errors contained in high-throughput sequence data sets.
Our results support this prediction, but also show that region of parameter
space where the differences between linked and unlinked character models is
revealed is quite limited.


\section{Methods}

\subsection{Simulations of error-free data sets}
For our simulations, we assumed a simple two-tipped species tree
with one ancestral population with a constant effective size
of
\rootpopsize
that diverged at time \divtime into
two descendent populations (terminal branches) with constant
effective sizes of
\tippopsize[1]
and
\tippopsize[2]
\jrocomment{(Figure X)}.
For two diploid individuals sampled from each of the terminal
populations (4 sampled gene copies per population),
we simulated 100,000 orthologous biallelic characters under a finite-sites,
continuous-time Markov chain (CTMC) model of evolution.
We simulated 100 data sets comprised of loci of three different lengths---1000,
500, and 250 linked characters.
We assume each locus is effectively unlinked and has no intralocus
recombination, i.e., each locus evolved along a single gene tree that is
independent of the other loci, conditional on the species tree.
We chose this simple species tree model for our simulations to help ensure any
differences in estimation accuracy or precision were due to differences in
underlying linked and unlinked character models,
and \emph{not} due to differences in numerical algorithms for searching species
and gene tree space.
Furthermore, we simulated biallelic characters, because unlinked-character MSC
models
\citep{bryantInferringSpeciesTrees2012,Oaks2018ecoevolity}
that are most comparable to linked-character models
\citep{Heled2010,ogilvieStarBEAST2BringsFaster2017}
are limited to characters with (at most) two states.

We simulated the two-tipped species trees under a pure birth-process with a
birth rate of 10 using the \python package
\dendropy
\citep[Version 4.40; \jrocomment{XXX} branch commit eb69003;][]{Dendropy}.  
This is equivalent to the divergence time being Exponentially distributed with
a rate of 20.
We drew population sizes for each branch of the species tree from a Gamma 
distribution with a shape of 5.0 and mean of 0.002. We simulated 100, 200, and 
400 gene trees for the 1000, 500, and 250 locus length data sets respectively 
using the contained coalescent implemented in \dendropy.
We simulated linked biallelic character alignments using
\seqgen (Version 1.3.4)
\citep{rambautSeqGenApplicationMonte1997}
with a GTR model with base frequencies of A and C equal to 0 and base 
frequencies of G and T equal to 0.5. The transition rate for all base changes was 
0, except for the rate between G and T which was 1.0. 

\subsection{Introducing Site-pattern Errors}
From each simulated dataset described above, we created four datasets by 
introducing two types of errors at two levels of severity. The first type of 
error we introduced was changing singleton character patterns (i.e., characters 
for which one gene copy was different from the other seven gene copies) to invariant 
patterns by changing the singleton character state to match the other gene 
copies. We introduced this change with a probability of 0.2 and 0.4 to create 
two datasets from each simulated dataset. The second type of error we introduced 
was missing heterozygous gene copies. To do this, we randomly paired gene copies 
from within each species for each locus, and with a probability 
of 0.2 or 0.4 we randomly replaced one with the other.


\subsection{Inference}
For each simulated data set,
we approximated the posterior distribution of the divergence time (\divtime)
and effective population sizes
(\rootpopsize, \tippopsize[1], and \tippopsize[2])
under an
unlinked-character model using
\ecoevolity
\citep[Version 0.3.2; dev branch commit a7e9bf2;][]{Oaks2018ecoevolity}
and a linked-character model using the
\beast
\citep[Version 0.15.1;][]{ogilvieStarBEAST2BringsFaster2017} 
package in
\beastcore
\citep[Version 2.5.2;][]{bouckaertBEASTSoftwarePlatform2014}.
For both methods, we specified a CTMC model of character evolution and prior
distributions that matched the model and distributions from which the data were
generated.
The prior on the effective size of the root population in the original
implementation of \ecoevolity was parameterized to be relative to the mean
effective size of the descendant populations.
We added an option to \ecoevolity to compile a version where the prior is
specified as the absolute effective size of the root population,
which matches the model in \beast and the model we used to generate the data.

For \ecoevolity, we ran four independent Markov chain Monte Carlo (MCMC)
analyses with 75,000 steps and a sample frequency of 50 steps.
For \beast, we ran two independent MCMC analyses with 20 million steps and a
sample frequency of 5000 steps. 
To assess convergence and mixing of the \ecoevolity and \beast MCMC chains, we
computed the effective sample size
\citep[ESS;][]{Gong2014}
and potential scale reduction factor
\citep[PSRF; the square root of Equation 1.1 in][]{Brooks1998}
from the samples of each parameter, and considered an ESS value greater
than 200 and PSRF less than 1.2 \citep{gelman1998} to indicate adequate mixing
of a chain. 
Based on preliminary analyses of simulated data sets without errors,
we chose to discard the first 501 and 201 samples from
the MCMC chains of \ecoevolity and \beast, leaving 4000 and
7600 posterior samples for each data set, respectively.


\subsection{Simulating unlinked characters}
All of the simulations above violate the assumption of the \ecoevolity
model that all characters are unlinked
\citep{bryantInferringSpeciesTrees2012,Oaks2018ecoevolity}.
In order to help verify that the generative model of our simulation pipeline
matched the underlying model of \ecoevolity, and to confirm that any behavior
of the method was not being caused by the linkage violation,
we simulated an additional 100 data sets of 100,000 biallelic characters as
described above, except that the characters  were unlinked
(i.e., each character evolved along an independent gene tree).
From each of these, we created another data set where singleton site patterns
were converted to invariant sites with a probability of 0.4.
We analyzed each of these data sets with \ecoevolity as described above.

\subsection{Project repository}
The full history of this project has been version-controlled and is available
at
\url{https://github.com/}\highLight{XXXXXX},
and includes
all of the data and scripts necessary to produce our results.

\section{Results}

The 95\% credible intervals for divergence times and effective population 
sizes estimated from alignments without error in \beast had the expected 
frequentist coverage in that the true value was within approximately 95\% of the 
estimated credible intervals. 
This confirms that the sequence data were simulated under the same model as 
that used for inference in \beast. 


\subsection{MCMC convergence and mixing}
Most sets of \beast and \ecoevolity MCMC chains yielded samples of parameters with
a PSRF less than 1.2, indicative of convergence,
however, we do see poor mixing (ESS < 200) of the \beast chains as the length
of loci decreases \mainfigsp;
yellow indicates ESS < 200, red indicates PSRF > 1.2, green indicates both)
We only see evidence of poor mixing and convergence for \ecoevolity when
applied to data sets with errors.
This is in contrast to \beast, for which the frequency and degree of poor MCMC
behavior is largely unaffected by the type or severity of errors.
The proportion of \beast root effective population size estimates with ESS 
values less than 200 was high across all analyses \rootfigsp. 
Estimates of descendant effective population size had better ESS values across all 
analyses with the exception of estimates of small effective population sizes from 
250 bp loci \thetafigsp.

The accuracy and precision of parameter estimates by \ecoevolity was much greater
when all sites of the alignment were used than when a single SNP per locus was used \mainfigsp.  
There is no clear trend for the accuracy and precision of \ecoevolity estimates across the
different types and degress of error or the length of loci when using a single SNP per locus \mainfigsp. 

The accuracy and precision of divergence time estimates by \beast were very good for all 
alignment lengths and types and degrees error \timefigsp. 
When all of the data were used and there was no error \ecoevolity produced 
estimates with accuracy and precision comparable to \beast \timefigsp. 
However when alignments contained errors, \ecoevolity underestimated very recent 
divergence times with increasing severity as the degree of error increased \timefigsp. 

The accuracy and precision of estimates of descendant effective population sizes 
by \beast was lower than for time and was negatively affected by both types
of error for all descendant population sizes \thetafigsp.
The results for each type and degree of error were consistent across different 
locus lengths \thetafigsp.
\beast underestimated descendant effective population sizes with increasing severity 
as the degree of error increased \thetafigsp.
The accuracy and precision of descendant effective population sizes in 
\ecoevolity was comparable to \beast when all of 
the data were used and there was no error \thetafigsp. 
\ecoevolity was also negatively affected
by both types of error with increasing severity as the degree of error increased
and this impact was no affected by locus length.
Descendant effective population size estimates made from alignments with 40\%
missing singleton and 40\% missing heterozygote error wtih \beast had higher
accuracy and precision than estimates made with \ecoevolity \thetafigsp.   

\section{Discussion}

Consistent with what has been shown with previous work, \ecoevolity performed 
better when all sites were utilized despite violating the assumption that all 
sites are unlinked \citep{Oaks2018ecoevolity}. All parameter estimates were very
poor when only a single SNP per locus was used. 

As expected the linked-character model of \ecoevolity was more robust to model 
violation than the unlinked-character model of \beast and yielded less biased 
estimates of divergence time and effective population sizes. 
We only see bias at very recent divergence times, where \ecoevolity
underestimates the divergence time and overestimates the ancestral pop size.
This affect dissapears when divergence time is larger than about $8N_e\mu$.
This suggests that the unlinked model is sensitive to the errors
when lineages do not coalesce within the terminal branches,
but is robust to the errors when they do.

Inflated pop size of internal branch.
We are seeing values indicating an average divergence between individuals of up
to 3\% \rootfigs, which is much higher than our prior mean expectation (0.4\%).
Seeing such biologially unrealistically large internal pop sizes could indicate
biased divergence time estimates.
However, there is little information in the data about effective population sizes 
of ancestral branches; so, unfortunately, the parameter that might serve as an indicator
of a problem is going to have very large credible intervals.
But, many of our posterior estimates of root pop size are well beyond the
prior.

Unsurprisingly MCMC performance declines with decreasing decreasing locus length.
There is less information contained in the shorter loci to inform gene tree estimation 
and there would be expected to be more uncertaintly in gene tree estimation.
This uncertainly results in a wider distribution of parameter space over that
must be explored.
Poor MCMC performance in \beast does not appear to correlate with poor parameter 
estimates. The distribution of estimates is generally as good or better than those 
from \ecoevolity. 


%
The degree to which a dataset will be affected by error from missing heterozygotes
and missing singletons will be highly dependent on the depth of sequencing coverage
and on how the data are processed. 

There will be a lower probability of sampling both alleles at a locus when locus 
coverage is low. There may be a high probability of missing alleles from any 
locus in individuals with overall low coverage. 

Furthermore even if both alleles at a locus are sequenced, they must be sequenced
at high enough coverage to meet the filtering thresholds during data processing.
The method used to process and filter data could have an effect?
For example the program Stacks2 first identifies alleles then merges them 
together to create consensus loci \citep{rochetteStacksAnalyticalMethods2019}. 

Pyrad first aligns reads to identify loci and then calls variants from loci 
based on variant coverage \citep{PyRADeatonAssemblyNovo2014}.

There may be a difference in how low coverage and basecalling or mutational error in reads
affects different strategies to data processing.



%
Filtering of minor allele frequencies that do not meet a minimum threshold has 
been discussed as a way to eliminate the impact of basecalling and mutational 
error \citep{linckMinorAlleleFrequency2019}.
Filtering alleles with counts of less than 3 ensures that all alleles have been 
found in at least two diploid inidividuals which would minimize the incorporation 
of error into analyses \citep{rochetteStacksAnalyticalMethods2019}.
Minor allele frequency filtering of singleton sites would eliminate all sites 
and likely produce error much greater than that observed in our analyses.


%
It is reassuring to see affect of bias limited to small region of parameter 
space and only large at most severe error rates.
40\% error rates likely higher than real data sets (I think? citations?).
However, real data likely contain a mix of errors/biases from
various steps in data collection process. We did not evaluate the how mutational
error or inaccurate base calls would bias estimates.
Also, real data would not be generated under a model with no prior misspecification.
Violations of the model might make methods more sensitive to lower rates of error.


What can investigators look for as warning signs that their results
are affected by such errors/biases?
- Low coverage at some loci or in some individuals

What can they do to avoid errors/biases?
It is important to obtain high coverage reduce the probability of allelic dropout
and missing singletons. 
Filter PCR clones which can account for as much as 60\% of sequenced reads 
\citep{andrewsHarnessingPowerRADseq2016, smithBiasedEstimatesClonal2014} by using single molecule tagging, randomly sheared libraries or PCR free
techniques.

Our results raise interesting questions that can be further explored\ldots
\begin{itemize}
    \item Larger trees. Will non-root internal branches suffer from bias, or
        only the root? Will only branches ancestral to short branches suffer?
        Will linked-site models remain robust?
        Will biased div times and pop sizes also affect accuracy of topology
        estimates?
    \item Acquisition biases. E.g., removing most variable loci to avoid
        paralogy. Will this only have an affect at recent times? Or will
        this affect be more pervasive across parameter space?
        Will linked-site models remain robust
    \item What erroneous site patterns have the largest affect on
        the likelihood? Can we model and correct for these?
    \item Are larger population sample sizes more robust? Perhaps it is better
        to sequence a larger number of individuals at lower coverage.
    \item We essentially had no model misspecification.
        what happens when our priors are wrong/diffuse?
        Will this amplify affect of errors/biases?
\end{itemize}

\highLight{We need citations. The discussion should compare/contrast with
    previous findings and put our findings in the context of the
    field.}
