\section{Introduction}

% How does an MSA model compare to BC model as the number and length of loci
% change?

% When we have multi-locus sequence data, should we analyze all the data under
% a biallelic-character model, or only keep (at most) one site per locus?

% How do MSA and BC models compare in term of robustness to data-acquistion
% biases?
% BC can be very sensitive \citep{Oaks2018ecoevolity}.
% Will MSA fair better?
% Information from each site under a BC model is the counts of alleles.
% Thus, it's not surprising these models are sensitive when these counts are off.
% BC gleans information from many sites to directly inform the species
% tree by integrating out the gene trees; we have very little information
% about any of the gene trees.
% In comparison, information from aligned sequences of linked sites can
% potentially contain much more information about the underlying gene tree.
% Thus, if an acquistion bias causes some tips to be missing, the
% information in the gene tree and branch lengths from the remaning
% sequences might allow us to recover.

Likelihood-based inference under the multispecies coalescent is a powerful 
framework for estimating species trees,  divergence times, and  effective 
population sizes in the presence of incomplete lineage sorting 
\citep{xuChallengesSpeciesTree2016}.
\jrocomment{More intro to phylogenetics/species trees here}

Likelihood-based approaches to species 
tree inference can be classified into two groups, based on how they model the 
evolution of orthologous DNA sites along gene trees within the species 
tree---those that assume (1) each site evolved along its own gene tree 
(i.e., each site is ``unlinked'') 
\citep{bryantInferringSpeciesTrees2012, maioPoMoAlleleFrequencyBased2015}, 
or (2) contiguous, linked sites evolved along a shared gene tree 
\citep{liuSpeciesTreesGene2007, Heled2010, ogilvieStarBEAST2BringsFaster2017, 
yangBPPProgramSpecies2015}. We will refer to these as unlinked and 
linked-character models, respectively. For both models, the gene tree of each 
locus (whether each locus is a single site or a segment of linked sites) 
is assumed to be independent of the gene 
trees of all other loci, conditional on the species tree.
Methods using linked character models become computationally expensive as the
number of loci grows large, due to the estimation or numerical integration of
all of the gene trees \citep{bryantInferringSpeciesTrees2012}.
Unlinked-character models on the other 
hand are more tractable for a large number of loci, because  estimating 
individual gene trees is avoided by integrating over all possible gene trees 
\citep{bryantInferringSpeciesTrees2012}.
Whereas unlinked-character models can accomodate a larger number of loci than
linked-character models, most genetic data sets comprise linked sites and
unlinked-character models are unable to utilize this information.

Reduced-representation genomic data sets acquired from high-throughput
instruments are becoming commonplace in phylogenetics \citep{Leache2017}, and
usually comprise hundreds to thousands of loci as short as 50 nucleotides long
and up to several thousand base pairs long.
Investigators are thus faced with decisions about how best to 
use their data to infer a species tree.
Should they use a linked-character method that assumes the sites within each
locus evolved along a shared gene tree?
Ideally, the answer would be ``yes,'' however this is not always
computationally feasible and the model could be violated by intralocus
recombination.
Alternatively, should investigators remove all but a single-nucleotide
polymorphism (SNP) from each locus and use an unlinked-character model?
Or, perhaps they should apply the unlinked-character method to all of their
sites, even if this violates the assumption that each site evolved along an
independent gene tree?
Little work has been done to help inform these types of decisions. 

An important consideration for choosing a multi-species coalescent model is
sources of error and bias that result from reduced-representation protocols,
high-throughput sequencing technologies, and the processing of these data.
\jrocomment{Blurb about PCR biases/error?}
Current high-throughput sequencing technologies have high rates of error.
For example, Illumina sequencing platforms have been shown to have error rates
as high as 0.25\% per base 
\citep{pfeifferSystematicEvaluationError2018}. 
To avoid introducing sequencing errors into analyses performed with the data, it is not 
uncommon to filter out variants that are not found above some minimum frequency 
threshold \citep{rochetteStacksAnalyticalMethods2019, linckMinorAlleleFrequency2019}. 
This filtering can also introduce errors and biases which has been 
shown to have an effect on estimates derived from the assembled alignments
\citep{Harvey2015,linckMinorAlleleFrequency2019}.
Furthermore, decisions have to be made during or after processing
the raw sequence reads to avoid aligning paralogous sequences.
This is often done by setting an upper threshold on the number of variable
sites within a locus \citationNeeded.
Such a strategy will also filter out the most variable alignments
of orthologous loci, thus introducing an acquisition bias.

% Sequence coverage---the mean number of unique reads representing each locus---is
% often highly variable among loci and among individuals. Higher coverage increases 
% confidence of calling variants and distinguishing variants from error. 
% At low coverage true variants not present at frequencies meeting the minimum threshold
% may be filtered by processing tools 

Given all of these potential problems throughout the data collection process,
phylogeneticists should assume their high-throughput genomic data set suffers
from errors and acquisition biases.
Do linked and unlinked character models differ in their robustness to such
errors?
Linked-character models can leverage shared information among linked sites
about each underlying gene tree.
Thus, these models may be able to correctly infer the general shape and depth
of a gene tree, even if the haplotypes at some of the tips have errors.
Unlinked character models have very little information about each gene tree,
and rely on the frequency of allele counts across many characters to inform the
model about the relative probabilities of all possible gene trees
(\jrocomment{Figure showing this difference?}).
Given this reliance on accurate allele count frequencies, we predict that
unlinked character models will be more sensitive to errors and acquisition
biases in genomic data.
Our goal is to simulate data sets with varying degrees of errors length of loci
to test this prediction that linked character models are more robust to the
types of errors contained in high-throughput sequence data sets.
Our results support this prediction, but also show that region of parameter
space where the differences between linked and unlinked character models is
revealed is quite limited.


\section{Methods}
\subsection{Simulations of error-free data sets}
For our simulations, we assumed a simple two-tipped species tree
with one ancestral population with a constant effective size
of
\rootpopsize
that diverged at time \divtime into
two descendent populations (terminal branches) with constant
effective sizes of
\tippopsize[1]
and
\tippopsize[2]
\jrocomment{(Figure X)}.
For two diploid individuals sampled from each of the terminal
populations (4 sampled gene copies per population),
we simulated 100,000 orthologous biallelic characters under a finite-sites,
continuous-time Markov chain (CTMC) model of evolution.
We simulated 100 data sets comprised of loci of three different lengths---1000,
500, and 250 linked characters.
We assume each locus is effectively unlinked and has no intralocus
recombination, i.e., each locus evolved along a single gene tree that is
independent of the other loci, conditional on the species tree.
We chose this simple species tree model for our simulations to help ensure any
differences in estimation accuracy or precision were due to differences in
underlying linked and unlinked character models,
and \emph{not} due to differences in numerical algorithms for searching species
and gene tree space.
Furthermore, we simulated biallelic characters, because unlinked-character MSC
models
\citep{bryantInferringSpeciesTrees2012,Oaks2018ecoevolity}
that are most comparable to linked-character models
\citep{Heled2010,ogilvieStarBEAST2BringsFaster2017}
are limited to characters with (at most) two states.

We simulated the two-tipped species trees under a pure birth-process with a
birth rate of 10 using the \python package
\dendropy
\citep[Version 4.40; \jrocomment{XXX} branch commit eb69003;][]{Dendropy}.  
This is equivalent to the divergence time being Exponentially distributed with
a rate of 20.
We drew population sizes for each branch of the species tree from a Gamma 
distribution with a shape of 5.0 and mean of 0.002. We simulated 100, 200, and 
400 gene trees for the 1000, 500, and 250 locus length data sets respectively 
using the contained coalescent implemented in \dendropy.
We simulated linked biallelic character alignments using
\seqgen (Version 1.3.4)
\citep{rambautSeqGenApplicationMonte1997}
with a GTR model with base frequencies of A and C equal to 0 and base 
frequencies of G and T equal to 0.5. The transition rate for all base changes was 
0, except for the rate between G and T which was 1.0. 

\subsection{Introducing Site-pattern Errors}
From each simulated dataset described above, we created four datasets by 
introducing two types of errors at two levels of severity. The first type of 
error we introduced was changing singleton character patterns (i.e., characters 
for which one gene copy was different from the other seven gene copies) to invariant 
patterns by changing the singleton character state to match the other gene 
copies. We introduced this change with a probability of 0.2 and 0.4 to create 
two datasets from each simulated dataset. The second type of error we introduced 
was missing heterozygous gene copies. To do this, we randomly paired gene copies 
from within each species for each locus, and with a probability 
of 0.2 or 0.4 we randomly replaced one with the other.


\subsection{Inference}
For each simulated data set,
we approximated the posterior distribution of the divergence time (\divtime)
and effective population sizes
(\rootpopsize, \tippopsize[1], and \tippopsize[2])
under an
unlinked-character model using
\ecoevolity
\citep[Version 0.3.2; dev branch commit a7e9bf2;][]{Oaks2018ecoevolity}
and a linked-character model using the
\beast
\citep[Version 0.15.1;][]{ogilvieStarBEAST2BringsFaster2017} 
package in
\beastcore
\citep[Version 2.5.2;][]{bouckaertBEASTSoftwarePlatform2014}.
For both methods, we specified a CTMC model of character evolution and prior
distributions that matched the model and distributions from which the data were
generated.
The prior on the effective size of the root population in the original
implementation of \ecoevolity was parameterized to be relative to the mean
effective size of the descendant populations.
We added an option to \ecoevolity to compile a version where the prior is
specified as the absolute effective size of the root population,
which matches the model in \beast and the model we used to generate the data.
We ran four independent chains of \ecoevolity with 75,000 steps and a sample 
frequency of 50 steps.
We ran two independent chains of \beast with 20 million steps and a 
sample frequency of 5000 steps. 


\section{Results}

We conservatively discarded the first 501 samples from the posterior of each 
\ecoevolity chain leaving 1,000 samples for each of the four chains and a combined
total of 4000.
We conservatively discarded the first 201 samples from the posterior of each 
\beast chain leaving 3,800 samples for each of the two chains and a combined
total of 7,600.

The 95\% credible intervals for divergence times and effective population 
sizes estimated from alignments without error in \beast had the expected 
frequentist coverage in that the true value was within approximately 95\% of the 
estimated credible intervals. 
This confirms that the sequence data were simulated under the same model as 
those used for inference in \beast. 

We computed the effective sample size (ESS) for each parameter estimate and considered
a value of 200 to indicate adequate mixing of a chain. 
We also computed the potential scale reduction factor (PSRF) for each estimate 
considered a value of less than 1.2 to indicate adequate convergence of 
independent chains \citep{gelman1998}. 
The effective sample size was greater than 200 for most \ecoevolity parameter
estimates regardless of locus length and type of or amount of error. 
Likewise the potential scale reduction factor was less than 1.2 for most \ecoevolity parameter estimates.

The proportion of estimates with PSRF values greater than 1.2 was very low across 
all \beast analyses indicating convergence of most chains.
The proportion of \beast divergence time estimates with ESS values less than 200 
increased at more recent divergence times as locus length decreased but were 
consistent across different types and degrees of error.
The proportion of \beast root effective population size estimates with ESS 
values less than 200 was high across all analyses. 
Estimates of descendant effective population size had better ESS values across all 
analyses with the exception of estimates of small effective population sizes from 
250 bp loci.

The accuracy and precision of parameter estimates by \ecoevolity was much greater
when all sites of the alignment were used than when a single SNP per locus was used.  
There is no clear trend for the accuracy and precision of \ecoevolity estimates across the
different types and degress of error or the length of loci when using a single SNP per locus. 

The accuracy and precision of divergence time estimates by \beast were very good for all 
alignment lengths and types and degrees error. 
When all of the data were used and there was no error \ecoevolity produced 
estimates with accuracy and precision comparable to \beast. 
However when alignments contained errors, \ecoevolity underestimated very recent 
divergence times with increasing severity as the degree of error increased. 

The accuracy and precision of estimates of descendant effective population sizes 
by \beast was lower than for time and was negatively affected by both types
of error for all descendant population sizes.
The results for each type and degree of error were consistent across different 
locus lengths.
\beast underestimated descendant effective population sizes with increasing severity 
as the degree of error increased.
The accuracy and precision of \ecoevolity was comparable to \beast when all of 
the data were used and there was no error. \ecoevolity was also negatively affected
by both types of error with increasing severity as the degree of error increased
and this impact was no affected by locus length.
Descendant effective population size estimates made from alignments with 40\%
missing singleton and 40\% missing heterozygote error wtih \beast had higher
accuracy and precision than estimates made with \ecoevolity.   

% Ecoevolity 1 bp







Time results for 1000bp loci (Figure~\ref{fig:time1000}).

Time results for 500bp loci (Figure~\ref{fig:time500}).

Time results for 250bp loci (Figure~\ref{fig:time250}).

\section{Discussion}

As expected the linked-sequence model was more robust to model violation.

But only in a small range of parameter space when divergence time is recent. This
is around the mean coalescent time

Ecoevolity performs better when all of the data are used as it results in a much larger 
amount of data. It has previously been shown that including all sites including 
constant sites has a great positive impact than simply addding more data that 
do not violate the model \citep{Oaks2018ecoevolity}

Unsurprisingly MCMC performance declines with decreasing decreasing locus length.
There is less information contained in the shorter loci to inform gene tree estimation 
and there would be expected to be more error in gene tree estimation.

Poor MCMC performance in \beast does not appear to correlate with poor parameter 
estimates. The distribution of estimates is generally as good or better than those 
from \ecoevolity. 

Comparison of run times???

How is the frequency of the 9 possible site patterns varying, especially with time

As loci get longer, there is more information and the posterior has a more 
narrow range and is easier for MCMC.

Practitioners may want to compare both models if the number of loci and taxa
permit it. Or maybe perform analyses on parts of the tree with recent divergence
time to compare results 
